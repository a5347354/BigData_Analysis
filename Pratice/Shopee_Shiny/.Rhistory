df
ordersMoney_groupby = df %>% group_by(訂單成立時間) %>% summarise(訂單小計 = sum(訂單小計))
ordersMoney_groupby
names(ordersMoney_groupby[1])
names(ordersMoney_groupby[,1])
names(ordersMoney_groupby[1,])
ordersMoney_groupby
ordersMoney_groupby[,1]
class(ordersMoney_groupby[,1])
class(as.vector(ordersMoney_groupby[,1])
d
class(as.vector(ordersMoney_groupby[,1]))
class(names(ordersMoney_groupby[,1]))
names(ordersMoney_groupby[,1])
ordersMoney_groupby[,2]
runApp()
runApp()
runApp()
table(ordersMoney_groupby[,1])
table(ordersMoney_groupby[,2])
as.numeric(names(table(ordersMoney_groupby[,2]))))
as.numeric(names(table(ordersMoney_groupby[,2])))
runApp()
runApp()
runApp()
runApp()
categories
categories = unique(orders$付款方式)
categories
runApp()
runApp()
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
library(rsconnect)
rsconnect::setAccountInfo(name='apollofan',
token='C84E5BE58EABBB6DE9409773FBC8F4ED',
secret='CL83kfi2Gq89s/Fg3ORgtP+c7YsBVn7AWwHdXqYu')
deployApp()
runAPP()
runApp()
library(googleVis)
library(dplyr)
library(reshape)
library(plotly)
library(shiny)
runApp()
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(orders)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
categories
categories
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
categories = unique(orders$付款方式) %>% unlist()
categories
categories[1]
categories[2]
categories[1,]
categories[,1]
categories[,1]
categories = unique(orders$付款方式) %>% as.vector()
categories
runApp()
runApp()
runApp()
orders = orders[,-c(1,2,3,4,11,12,13,17)]
View(orders)
runApp()
runApp()
products = c("養樂多軟糖",
"怪獸",
"香脆點心麵",
"火雞辣拌麵",
"Enaak",
"農心炸醬麵",
"迷你香蕉巧克力棒",
"預感洋芋片",
"檸檬片",
"黑旋風巧克力棒",
"香蕉巧克力派")
products
abc(products) = function(e){orders_selected[grepl(e,orders$商品資訊),]}
View(orders)
orders
View(orders)
orders[1,6]
orders[6,1]
test = orders[1,6]
test
test[1]
test = orders[1,6] %>% unlist()
test
gsub('.價格.',x = test)
grep('.價格.',x = test)
grep(".'價格:'.",x = test)
grep(".'價格:'(\\w);.",x = test)
grep(".價格:(\\w);.",x = test)
grep(".價格:(.);.",x = test)
grep("價格:(.);",x = test)
grep("^價格:(.);$",x = test)
grep("^價格:(.);$",x = test[1])
grep("^價格:(.);$",x = as.vector(test))
class(test)
test
grep("^價格:(.);",x = as.vector(test))
grep("?價格:(.);?",x = as.vector(test))
x =grep("?價格:(.);?",x = as.vector(test))
x
x = "Qoo@coke.com"
grep("( \\w + ? ) @ ( . + )",x= x)
grep("(\\w+?)@(.+)",x= x)
gsub("(\\w+?)@(.+)","\\1\\2",x= x)
gsub("(\\w+?)@(.+)","\\1",x= x)
gsub("(\\w+?)@(.+)","\\2",x= x)
gsub("?價格:(.);?","\\1",x = as.vector(test))
gsub(".價格:(.);.","\\1",x = as.vector(test))
gsub(".價格: NT(.+);.","\\1",x = as.vector(test))
gsub(".價格: NT(.+);.","\\1",x = test)
gsub(".?價格: NT(.+);.","\\1",x = test)
gsub("[1].?價格: NT(.+);.[2]","\\1",x = test)
gsub("^[1].?價格: NT(.+);.[2]","\\1",x = test)
gsub("^[1].?價格: NT(.+);.[2]$","\\1",x = test)
gsub("[1].價格:(.);.[2]","\\1",x = test)
sub("[1].價格:(.);.[2]","\\1",x = test)
sub("[1].NT:(.);.[2]","\\1",x = test)
sub("[1].+NT$(.);.[2]","\\1",x = test)
sub("/價格/","\\1",x = test)
sub("/價格:/(.).\s","\\1",x = test)
sub("/價格:/(.).","\\1",x = test)
sub("/價格:/","\\1",x = test)
x
class(x)
class(test)
sub("/價格:/","\\1",x = as.character(test)
sub("/價格:/","\\1",x = as.character(test)
sub("/價格:/","\\1",x = as.character(test))
sub(".價格:.","\\1",x = as.character(test))
sub(".價格:.NT $(.);.","\\1",x = as.character(test))
sub(".價格:.NT \$(.);.","\\1",x = as.character(test))
sub(".價格:.NT (.);.","\\1",x = as.character(test))
sub(".價格:(.);.","\\1",x = as.character(test))
sub(".價格:(.).","\\1",x = as.character(test))
x = sub(".價格:(.).","\\1",x = as.character(test))
x
library("jiebaR", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
edit_dict()
jeba.dict.utf8
DICTPATH
runApp()
str_match('123文字雲','[\u4e00-\u9fa5]')
library(stringr)
str_match('123文字雲','[\u4e00-\u9fa5]')
library(stringr)
str_match('123文字雲','[\u4e00-\u9fa5]+')
library(stringr)
str_match('123文字雲','[\u4e00-\u9fa5]+')
str_match('文123字雲','[\u4e00-\u9fa5]+')
fit = rpart(Species ~ Sepal.Length + Sepat.width + Petal.Length + Petal.width, data = iris)
install.packages("part")
library(rpart)
data(iris)
fit = rpart(Species ~ Sepal.Length + Sepat.width + Petal.Length + Petal.width, data = iris)
library(rpart)
data(iris)
fit = rpart(Species ~ Sepal.Length + Sepal.width + Petal.Length + Petal.width, data = iris)
fit = rpart(Species ~ Sepal.Length + Sepal.width + Petal.Length + Petal.Width, data = iris)
fit = rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
fit
library(rpart)
data(iris)
fit = rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
fit
polt(fit, margin = 0.1)
text(fit)
library(rpart)
data(iris)
fit = rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
fit
plot(fit, margin = 0.1)
text(fit)
library(rpart)
data(iris)
fit = rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
fit
plot(fit, margin = 1)
text(fit)
library(rpart)
data(iris)
fit = rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
fit
plot(fit, margin = 0)
text(fit)
plot(iris$Petal.Length, iris$Petal.Width)
plot(iris$Petal.Width, iris$Petal.Width,col = iris$Species)
fit
abline(v=2.45,col="blue")
abline(h=1.75,col="orange")
library(rpart)
data(iris)
#目標放在左邊Secies，變量放右邊
fit = rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
fit
plot(fit, margin = 0)
text(fit)
library(rpart)
data(iris)
#目標放在左邊Secies，變量放右邊
fit = rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, data = iris)
fit
plot(fit, margin = 0.1)
text(fit)
predict(fit,data,frame(Petal.Length = 1,Petal.Length = 1, Sepal.Length = 1,Sepal.Width = 1))
predict(fit,data.frame(Petal.Length = 1,Petal.Length = 1, Sepal.Length = 1,Sepal.Width = 1))
predict(fit,data.frame(Petal.Length = 1,Petal.Width = 1, Sepal.Length = 1,Sepal.Width = 1))
predict(fit, iris[,-5],type = 'class')
cm = table(iris[,5],predict(fit,iris[,5],type = 'class'))
install.packages('caret')
cm = table(iris[,5],predict(fit, iris[,5], type = 'class'))
#類別
predict(fit, iris[,-5],type = 'class')
#機率
predict(fit, iris[,-5],type = 'prob')
cm = table(iris[,5],predict(fit, iris[,5], type = 'class'))
iris[,5]
fit
ind = sample(c(1,2),150,replace = TRUE, prob = c(0.7,0.3))
ind == 1
trainset = iris[ind == 1,]
testset = iris[ind == 2,]
cllass(ind)
class(ind)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
repeats = 10)
library(caret)
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
fit
predict(fit, data.frame(Petal.Length = 1, Petal.Width = 1, Sepal.Length = 1, Sepal.Width = 1))
#類別
predict(fit, iris[,-5],type = 'class')
#機率
predict(fit, iris[,-5],type = 'prob')
#產生混淆矩陣
cm = table(iris[,5],predict(fit, iris[,5], type = 'class'))
#類別
predict(fit, iris[,-5],type = 'class')
#機率
predict(fit, iris[,-5],type = 'prob')
predict(fit, data.frame(Petal.Length = 1, Petal.Width = 1, Sepal.Length = 1, Sepal.Width = 1))
#類別
predict(fit, iris[,-5],type = 'class')
#機率
predict(fit, iris[,-5],type = 'prob')
#產生混淆矩陣
cm = table(iris[,5],predict(fit, iris[,5], type = 'class'))
predict(fit, data.frame(Petal.Length = 1, Petal.Width = 1, Sepal.Length = 1, Sepal.Width = 1))
#類別
predict(fit, iris[,-5],type = 'class')
#機率
predict(fit, iris[,-5],type = 'prob')
#產生混淆矩陣
cm = table(iris[,5],predict(fit, iris[,5], type = 'class'))
predict(fit, data.frame(Petal.Length = 1, Petal.Width = 1, Sepal.Length = 1, Sepal.Width = 1))
#類別
predict(fit, iris[,-5],type = 'class')
#機率
predict(fit, iris[,-5],type = 'prob')
#產生混淆矩陣
cm = table(iris[,5],predict(fit, iris[,5], type = 'class'))
cm = table(iris[,5], predict(fit, iris[,-5], type='class'))
install.packages('caret', repo='http://nbcgib.uesc.br/mirrors/cran/')
install.packages('e1071', repo='http://nbcgib.uesc.br/mirrors/cran/')
install.packages("caret")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
detach("package:caret", unload=TRUE)
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages('caret', repo='http://nbcgib.uesc.br/mirrors/cran/')
install.packages('e1071', repo='http://nbcgib.uesc.br/mirrors/cran/')
install.packages('caret', repo='http://nbcgib.uesc.br/mirrors/cran/')
install.packages('e1071', repo='http://nbcgib.uesc.br/mirrors/cran/')
remove.packages("caret")
install.packages("caret")
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("car", dependencies=TRUE)
library(caret)
fitControl <- trainControl(## 10-fold CV
method = "repeatedcv",
number = 10,
repeats = 10)
rpartFit <- train(Species ~ ., data = iris,
method = "rpart",
trControl = fitControl)
rpartFit
cm = table(predict(rpartFit, iris), iris[,5])
confusionMatrix(cm)
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("car")
install.packages('car', repo='http://nbcgib.uesc.br/mirrors/cran/')
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
detach("package:caret", unload=TRUE)
library("caret", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.packages("pbkrtest")
library("pbkrtest", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(caret)
remove.packages("pbkrtest")
install.packages("C50")
data(churn)
str(churnTrain)
#拿掉區碼、區域等欄位
churnTrain = churnTrain[,! names(churnTrain) %in% c("state", "area_code", "account_length") ]
set.seed(2)
#分割資料
ind <- sample(2, nrow(churnTrain), replace = TRUE, prob=c(0.7, 0.3))
trainset = churnTrain[ind == 1,]
testset = churnTrain[ind == 2,]
library(C50)
data(churn)
str(churnTrain)
churnTrain = churnTrain[,! names(churnTrain) %in% c("state", "area_code", "account_length") ]
set.seed(2)
ind <- sample(2, nrow(churnTrain), replace = TRUE, prob=c(0.7, 0.3))
trainset = churnTrain[ind == 1,]
testset = churnTrain[ind == 2,]
churn.rp <- rpart(churn ~ ., data=trainset)
plot(churn.rp, margin= 0.1)
text(churn.rp, all=TRUE, use.n = TRUE)
library(rpart)
#建立分類樹
churn.rp <- rpart(churn ~ ., data=trainset)
plot(churn.rp, margin= 0.1)
text(churn.rp, all=TRUE, use.n = TRUE)
##建立分類樹
#值越低，代表越能將Yes/No切開來
min(churn.rp$cptable[,"xerror"])
which.min(churn.rp$cptable[,"xerror"])
#只留7個分枝
churn.cp = churn.rp$cptable[7,"CP"]
prune.tree = prune(churn.rp, cp= churn.cp)
plot(prune.tree, margin= 0.1)
text(prune.tree, all=TRUE , use.n=TRUE)
prune.tree
plotly(prune.tree)
install.packages("caret")
library(caret)
ac = (50+49+45)/(50+50+50)
#install.packages('caret')
library(caret)
confusionMatrix(cm)
install.packages("e1071")
library(ROCR)
predictions <- predict(churn_rp, testset, type="prob")
yes <- predictions[, 1]
pred_rocr <- prediction(yes, as.factor(testset[,(dim(testset)[[2]])]))
perf_rocr <- performance(pred_rocr, measure = "auc", x.measure = "cutoff")
#產生圖
perf_tpr_rocr <- performance(pred_rocr, "tpr","fpr")
plot(perf_tpr_rocr, colorize=T,main=paste("AUC:",(perf_rocr@y.values)))
install.packages("ROCR")
head(predict(churn.rp, testset, type="prob"))
x = c()
y = c()
for (threshold in seq(0.1,0.9,0.1)){
yes = predict(churn.rp, testset, type="prob")[,1]
pred = ifelse(yes > threshold, 0, 1)
pred = factor(pred, labels =c('yes', 'no'))
ct = table(pred, testset$churn)
cm = confusionMatrix(ct)
y = c(y, cm$byClass[1])
x = c(x, 1 - cm$byClass[2])
}
plot(x,y)
lines(x,y, col="red")
##列出是否有對到該詞的，輸出yes/no
download.file('https://raw.githubusercontent.com/ywchiu/rtibame/master/Data/appledaily.RData', 'appledaily.RData')
load('appledaily.RData')
apple_subset = appledaily[appledaily$category %in% c('財經','娛樂','社會'),]
table(apple_subset$category)
library(jiebaR)
mixseg = worker()
apple_seg =lapply(apple_subset$content, function(e)segment(code=e, jiebar=mixseg))
source('https://github.com/ywchiu/rtibame/raw/master/Lib/CNCorpus.R')
doc=CNCorpus(apple_seg)
doc=unlist(tm_map(doc,jieba_tokenizer),recursive=F)
doc=lapply(doc,function(d)paste(d,collapse=' '))
control_list=list(wordLengths=c(2,Inf),tokenize=space_tokenizer)
dtm=DocumentTermMatrix(Corpus(VectorSource(doc)),control=control_list)
dim(dtm)
ft <- findFreqTerms(dtm, 5)
control_list=list(wordLengths=c(2,Inf),tokenize=space_tokenizer,dictionary =ft)
new_dtm=DocumentTermMatrix(Corpus(VectorSource(doc)),control=control_list)
dim(new_dtm)
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return(x)
}
dtm_count <- apply(new_dtm, MARGIN = 2, convert_counts)
library(e1071)
#轉型
m <- as.data.frame(dtm_count)
#分割資料，分成兩群
idx <- sample.int(2, nrow(m), replace=TRUE, prob=c(0.7,0.3))
trainset <- m[idx==1,]
testset <- m[idx==2,]
traintitle <- apple_subset[idx==1,"title"]
testtitle <- apple_subset[idx==2,"title"]
traintag <- apple_subset[idx==1,"category"]
testtag <-apple_subset[idx==2,"category"]
#轉換
traintag = as.factor(traintag)
testtag = as.factor(testtag)
traintag <- apple_subset[idx==1,"category"]
testtag <-apple_subset[idx==2,"category"]
dim(trainset)
dim(testset)
library(e1071)
model= naiveBayes(trainset, traintag)
#預測
pred = predict(model, testset)
cm = table(pred,testtag)
pred
testtag
pred
pred = predict(model, testset)
pred
model
testset
table(pred,testtag)
library(e1071)
#轉型
m <- as.data.frame(dtm_count)
#分割資料，分成兩群
idx <- sample.int(2, nrow(m), replace=TRUE, prob=c(0.7,0.3))
trainset <- m[idx==1,]
testset <- m[idx==2,]
traintitle <- apple_subset[idx==1,"title"]
testtitle <- apple_subset[idx==2,"title"]
traintag <- apple_subset[idx==1,"category"]
testtag <-apple_subset[idx==2,"category"]
#轉換
traintag = as.factor(traintag)
testtag = as.factor(testtag)
dim(trainset)
dim(testset)
library(e1071)
model= naiveBayes(trainset, traintag)
#預測
pred = predict(model, testset)
cm = table(pred,testtag)
tessttitle[pred !=testtag]
pred[pred != testtag]
which(pred != tesstag)
new.dtm$dimnames$Terms
testtitle[pred !=testtag]
pred[pred != testtag]
which(pred != testtag)
new.dtm$dimnames$Terms
library(httr)
a = GET('http://mall.shopee.tw/search/api/items/?page_type=search&match_id=2209&keyword=&shop_categoryids=&hashtag=&facet_type=&by=pop&order=desc&newest=20&limit=50&need_drop_word=false')
library(rjson)
library("jsonlite", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
content(a)
fromjson(content(a))
fromJSON(content(a))
fromJSON(a)
a
fromJSON(content(a))
a = fromJSON('http://mall.shopee.tw/search/api/items/?page_type=search&match_id=2209&keyword=&shop_categoryids=&hashtag=&facet_type=&by=pop&order=desc&newest=20&limit=50&need_drop_word=false')
a
a$items
library(stringr)
str_match_all('Swift程式設計入門繁體中文，彼得潘，松崗出版日期：2015-03-19; $450 ;售價: NT $342; 16-02-29', '售價: NT $(\\d+)')
str_match_all('\$(\\d+)', 'Swift程式設計入門繁體中文，彼得潘，松崗出版日期：2015-03-19; $450 ;售價: NT $342; 16-02-29')
str_match_all('\\$(\\d+)', 'Swift程式設計入門繁體中文，彼得潘，松崗出版日期：2015-03-19; $450 ;售價: NT $342; 16-02-29')
?str_match_all
str_match_all('; $450 ;售價: NT $342; 16-02-29','\\$(\\d+)')
str_match('文123字雲','[\u4e00-\u9fa50-9]+')
str_split('文123字雲', '[0-9]+')
pate0(str_split('文123字雲', '[0-9]+'))
paste0(str_split('文123字雲', '[0-9]+'))
paste0(str_split('文123字雲', '[0-9]+'), collapse='')
?psate0
?paste0
paste0(str_split('文123字雲', '[0-9]+'), collapse = ='')
paste0(str_split('文123字雲', '[0-9]+'), collapse = '')
str_match_all('; $450 ;售價: NT $342; 16-02-29','\\$(\\d+)')
